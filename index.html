<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="MALT: Improving Reasoning with Multi-Agent LLM Training">
  <meta property="og:title" content="MALT: Improving Reasoning with Multi-Agent LLM Training"/>
  <meta property="og:description" content="A novel post-training strategy that divides reasoning into generation, verification, and refinement steps using a pipeline of specialized agents."/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/framework.jpg" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="MALT: Improving Reasoning with Multi-Agent LLM Training">
  <meta name="twitter:description" content="A novel post-training strategy that divides reasoning into generation, verification, and refinement steps using a pipeline of specialized agents.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/framework.jpg">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="multi-agent learning, LLM, reasoning, AI training, MALT">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>MALT: Improving Reasoning with Multi-Agent LLM Training</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">MALT: Improving Reasoning with Multi-Agent LLM Training</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://sumeetmotwani.com">Sumeet Ramesh Motwani</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://chandlersmith.me/">Chandler Smith</a><sup>2</sup>,</span>
                  <span class="author-block">
                    <a href="https://rocktimjyotidas.github.io/">Rocktim Jyoti Das</a><sup>3</sup>,</span>
                    <span class="author-block">
                      <a href="https://rmrafailov.github.io/">Rafael Rafailov</a><sup>4</sup>,</span>
                      <span class="author-block">
                        <a href="https://www.di.ens.fr/~laptev/">Ivan Laptev</a><sup>3</sup>,</span>
                        <span class="author-block">
                          <a href="https://eng.ox.ac.uk/people/philip-torr/">Philip H. S. Torr</a><sup>1</sup>,</span>
                          <span class="author-block">
                            <a href="https://fabvio.github.io/">Fabio Pizzati</a><sup>1</sup>,</span>
                            <span class="author-block">
                              <a href="https://www.ron-clark.com/">Ronald Clark</a><sup>1</sup>,</span>
                              <span class="author-block">
                                <a href="https://schroederdewitt.com/">Christian Schroeder de Witt</a><sup>1</sup>
                              </span>
                              </div>

                              <div class="is-size-5 publication-authors">
                                <span class="author-block"><sup>1</sup>University of Oxford</span>
                                <span class="author-block"><sup>2</sup>Cooperative AI Foundation</span>
                                <span class="author-block"><sup>3</sup>MBZUAI</span>
                                <span class="author-block"><sup>4</sup>Stanford University</span>
                              </div>

                              <div class="column has-text-centered">
                                <div class="publication-links">
                                     <!-- Arxiv PDF link -->
                                  <span class="link-block">
                                    <a href="https://arxiv.org/abs/2412.01928" target="_blank"
                                    class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                      <i class="fas fa-file-pdf"></i>
                                    </span>
                                    <span>Paper</span>
                                  </a>
                                </span>

                              <!-- Github link -->
                              <span class="link-block">
                                <a href="#code" class="external-link button is-normal is-rounded is-dark">
                                  <span class="icon">
                                    <i class="fab fa-github"></i>
                                  </span>
                                  <span>Code (Coming Soon)</span>
                                </a>
                              </span>

                              <!-- HuggingFace link -->
                              <span class="link-block">
                                <a href="https://huggingface.co/papers/2412.01928" target="_blank" class="external-link button is-normal is-rounded is-dark">
                                  <span class="icon">
                                    <i class="fas fa-file-code"></i>
                                  </span>
                                  <span>HuggingFace</span>
                                </a>
                              </span>

                              <!-- Slides link -->
                              <span class="link-block">
                                <a href="https://docs.google.com/presentation/d/1iLNObTHILLcepUNO4Hi2Jwrpn1zRx0XtJpCM-zB-El8/edit?usp=sharing" target="_blank" class="external-link button is-normal is-rounded is-dark">
                                  <span class="icon">
                                    <i class="fas fa-image"></i>
                                  </span>
                                  <span>Slides</span>
                                </a>
                              </span>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                  </section>

                  <!-- Paper abstract -->
                  <section class="section">
                    <div class="container is-max-desktop">
                      <div class="columns is-centered has-text-centered">
                        <div class="column is-four-fifths">
                          <h2 class="title is-3">Abstract</h2>
                          <div class="content has-text-justified">
                            <p>
                              Large Language Models (LLMs) often produce answers with a single chain-of-thought, which restricts their ability to explore reasoning paths or self-correct flawed outputs in complex tasks. In this paper, we introduce MALT (Multi-Agent LLM Training), a novel post-training strategy that divides the reasoning process into generation, verification, and refinement steps using a sequential pipeline of heterogeneous agents. During data generation, each agent is repeatedly sampled to form a multi-agent search tree, where final outputs are graded against ground-truth data. We then apply value iteration to propagate reward signals back to each role-conditioned model, automatically producing multi-agent post-training data without human or teacher-model supervision. Our off-policy approach allows each agent to specialize by learning from correct and incorrect trajectories, ultimately improving the end-to-end reasoning chain. On MATH, GSM8K, and CSQA, MALT surpasses the same baseline LLM with a relative improvement of 15.66%, 7.42%, and 9.40% respectively, making it an important advance towards multi-agent cooperative training.
                            </p>
                          </div>
                        </div>
                      </div>
                    </div>
                  </section>

                  <!-- Framework Image -->
                  <section class="section">
                    <div class="container is-max-desktop">
                      <div class="columns is-centered">
                        <div class="column is-four-fifths">
                          <h2 class="title is-3">System Architecture</h2>
                          <div class="content has-text-centered">
                            <img src="static/images/framework.jpg" alt="MALT Framework"/>
                            <p class="caption">
                              MALT Method Overview. Given an input, we consider a three-agent system composed of a Generator for initial answer production, a Verifier providing a critique, and a Refinement Model integrating all intermediate reasoning steps into a final output. For questions in the training set, we introduce a tree search and credit assignment process (Left) to generate synthetic datasets with reasoning trajectory preference pairs for each model. These are used to post-train individual models (Center). During inference over the test-set, we perform three parallel sequential passes through the multi-agent setup, and return the final answer obtained via majority voting (Right).
                            </p>
                          </div>
                        </div>
                      </div>
                    </div>
                  </section>
                  <!-- End Framework Image -->

                  <!-- Results Analysis Section -->
                  <section class="section">
                    <div class="container is-max-desktop">
                      <div class="columns is-centered">
                        <div class="column is-four-fifths">
                          <h2 class="title is-3">Performance Analysis</h2>
                          <div class="content has-text-centered">
                            <img src="static/images/results.jpg" alt="MALT Performance Analysis"/>
                            <p class="caption">
                              Analysis of MALT performance. Left: Transition patterns showing how MALT improves correct answers while reducing incorrect ones. Right: Turn-wise accuracy analysis showing how Generator (G), Verifier (V), and Refinement (R) agents contribute to overall performance. MALT significantly outperforms baselines across all benchmarks.
                            </p>
                          </div>
                        </div>
                      </div>
                    </div>
                  </section>
                  <!-- End Results Analysis Section -->

                  <!-- Results Section -->
                  <section class="section">
                    <div class="container is-max-desktop">
                      <div class="columns is-centered">
                        <div class="column is-four-fifths">
                          <h2 class="title is-3">Results</h2>
                          <div class="content has-text-justified">
                            <!-- <p>
                              MALT demonstrates significant improvements over single-agent approaches on several challenging reasoning benchmarks:
                            </p> -->
                            
                            <!-- <div class="content has-text-centered">
                              <img src="static/images/results_table.png" alt="MALT Results"/>
                              <p class="caption">
                                Benchmark results. We compare MALT with baselines on three different benchmarks. For baselines, we include different setups such as single agent (SA) and multi-agent (MA), both with and without majority voting (MV). MALT outperforms all baselines.
                              </p>
                            </div> -->
                            
                            <p>
                              MALT achieves an accuracy of 57.25%, 81.50%, and 90.50% on MATH, CSQA, and GSM8K. Overall, MALT significantly outperforms all baselines, including all settings with supervised fine-tuned models. Over the base model's performance as a generator, MALT achieves relative improvements of 15.66%, 9.40%, and 7.42% on MATH, CSQA, and GSM8K. This demonstrates the reasoning efficacy of our search and attribution based data generation, post-training, and inference pipeline in MALT across benchmarks of varying difficulty.
                            </p>
                            
                            <ul>
                              <li><strong>MATH</strong>: 15.66% relative improvement</li>
                              <li><strong>GSM8K</strong>: 7.42% relative improvement</li>
                              <li><strong>CSQA</strong>: 9.40% relative improvement</li>
                            </ul>
                            
                            <p>
                              These results highlight the effectiveness of the multi-agent training approach in enhancing reasoning capabilities of LLMs, particularly for complex problem-solving tasks.
                            </p>
                          </div>
                        </div>
                      </div>
                    </div>
                  </section>
                  <!-- End Results Section -->

                  <!--BibTex citation -->
                  <section class="section hero is-light">
                    <div class="container is-max-desktop">
                      <div class="columns is-centered">
                        <div class="column is-four-fifths">
                          <h2 class="title is-3">BibTeX</h2>
                          <pre><code>@article{motwani2024malt,
  title={MALT: Improving Reasoning with Multi-Agent LLM Training},
  author={Motwani, Sumeet Ramesh and Smith, Chandler and Das, Rocktim Jyoti and Rafailov, Rafael and Laptev, Ivan and Torr, Philip H. S. and Pizzati, Fabio and Clark, Ronald and de Witt, Christian Schroeder},
  journal={arXiv preprint arXiv:2412.01928},
  year={2024}
}</code></pre>
                        </div>
                      </div>
                    </div>
                  </section>
                  <!--End BibTex citation -->

                  <!-- Correspondence -->
                  <section class="section">
                    <div class="container is-max-desktop">
                      <div class="columns is-centered">
                        <div class="column is-four-fifths">
                          <h2 class="title is-4">Correspondence</h2>
                          <div class="content has-text-justified">
                            <p>
                              For inquiries, please contact Sumeet Ramesh Motwani (<a href="mailto:sumeet.motwani@eng.ox.ac.uk">sumeet.motwani@eng.ox.ac.uk</a>) or Christian Schroeder de Witt (<a href="mailto:cs@robots.ox.ac.uk">cs@robots.ox.ac.uk</a>).
                            </p>
                          </div>
                        </div>
                      </div>
                    </div>
                  </section>
                  <!-- End Correspondence -->

                  <footer class="footer">
                  <div class="container">
                    <div class="columns is-centered">
                      <div class="column is-8">
                        <div class="content">
                          <p>
                            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
                          </p>
                        </div>
                      </div>
                    </div>
                  </div>
                </footer>

                <!-- Statcounter tracking code -->
                  
                <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

                    <!-- End of Statcounter Code -->

                  </body>
                  </html>
